{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1cc9bb4-ba73-4b21-a41b-60a80d7c9174",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implement logistic regression from scratch using torch\n",
    "## 3 steps for any model\n",
    "1) Design a model (input size, output size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Implement actual training\n",
    "    1) forward pass - compute prediction and loss\n",
    "    2) backward pass - compute gradients wrt loss\n",
    "    3) update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba072ce-6438-4a86-aaaf-e61b206069ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbcd524-70b0-4b62-b678-c952b379d1fb",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5a1bac-a380-4eee-adf8-afe7b71dd46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = datasets.load_breast_cancer() ## a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5530ccdf-e401-44af-ae3d-6d3781862c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = bc['data'], bc['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c41a4ba-cde4-40d8-a8ec-4b967e02a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726d338-5973-40df-9e10-c9260d3ae63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20b457-b6eb-4c7c-b398-4fe64c796ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01101e23-7c65-4eb1-8b7b-e81d954a0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59949551-93fc-423b-bed0-8162dea3463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5629a-f1ab-4749-a485-125ed4fbaeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale features using StandardScaler to make features 0 mean and unit variance\n",
    "## Use fit transform of StandardScaler on train dataset to get fitted mean and variance\n",
    "## and also transform train dataset. Use just transform on test data set with fitted scaler\n",
    "## to use train fitted mean and variance to transform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1fee05-fa39-4052-8bd9-f0060b68e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler() ## to make features 0 mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2350141-e230-4604-92c6-954af6bea19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f1f0e78-0138-4f90-9470-c13fefd5a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2c9193-f075-45f9-a4f7-511595234ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba2f70-f63f-4c2b-aae8-f944f8e5eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First have to convert numpy arrays into pytorch tensors\n",
    "## cast double to float 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "917119f8-708d-4e84-b7f2-5bbf711daf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train.astype(np.float32)) ## double to float 32\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32)) ## double to float 32\n",
    "\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32)) ## double to float 32\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32)) ## double to float 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2621c6b-e5bb-47ab-a225-eeb8a7e03ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## have to convert y to shape n,1 instead of just n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fef6895-8782-422c-a671-ba71b86260db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4040fb-0d1e-48b8-9880-0de5c63353a6",
   "metadata": {},
   "source": [
    "## Design model (input size, output size, forward pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a51298a-ab33-4aeb-831d-45895c2f2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 two parts : first f(x) = wx+b, then a sigmoid at end. only 1 hidden node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a821293-d503-4be1-9b9a-359ea8a387a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7596cc85-4fb4-497e-8c6f-016e1703100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54b461-6537-4fff-a0f7-bb2805f8c1e9",
   "metadata": {},
   "source": [
    "## Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1d689ad-a4a5-40d9-a919-509afeefcc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afde2ff-ff20-4cfb-809a-912f9c8c12ba",
   "metadata": {},
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae609d4b-b1cb-42e1-bd91-10a030bd7fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10, loss : 0.6830\n",
      "epoch : 20, loss : 0.5280\n",
      "epoch : 30, loss : 0.4392\n",
      "epoch : 40, loss : 0.3825\n",
      "epoch : 50, loss : 0.3429\n",
      "epoch : 60, loss : 0.3136\n",
      "epoch : 70, loss : 0.2908\n",
      "epoch : 80, loss : 0.2724\n",
      "epoch : 90, loss : 0.2573\n",
      "epoch : 100, loss : 0.2446\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    ## forward pass - compute prediction and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    \n",
    "    ## backward pass #3 compute local gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    ## weight updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    ## zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch + 1)%10==0:\n",
    "        print(f'epoch : {epoch + 1}, loss : {loss.item():.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c37db-5512-4fb5-9a35-203f0736f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(0.7)>0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf535e7-821e-4903-b587-9e6ac261bd5e",
   "metadata": {},
   "source": [
    "## inference/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68d58078-3238-4e7d-997c-e6bf2a32fbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8860\n"
     ]
    }
   ],
   "source": [
    "## threshold assumed to be 0.5\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round() ## rounds to 0 or 1\n",
    "    acc = y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59e38207-8f85-47bc-8150-2267dbe87039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(101)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_predicted_cls==y_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1369b97-cd6f-47da-a08f-695328eb7df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
